<!DOCTYPE html>
<html lang="fa" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>نسخه نمایشی هوش مصنوعی چندوجهی</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Vazirmatn:wght@400;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Vazirmatn', sans-serif;
        }
        /* استایل برای انیمیشن درخشان */
        @keyframes glowing {
            0% { box-shadow: 0 0 5px #2563eb, 0 0 10px #2563eb; }
            50% { box-shadow: 0 0 20px #2563eb, 0 0 30px #2563eb; }
            100% { box-shadow: 0 0 5px #2563eb, 0 0 10px #2563eb; }
        }
        .glowing-border {
            animation: glowing 2s infinite ease-in-out;
        }
    </style>
</head>
<body class="bg-gray-900 text-white flex flex-col items-center justify-center min-h-screen p-4">

    <div class="w-full max-w-4xl bg-gray-800 rounded-2xl shadow-2xl p-6 space-y-6">
        <h1 class="text-3xl font-bold text-center text-blue-400">شبیه‌ساز هوش مصنوعی انسان‌نما</h1>
        <p class="text-center text-gray-400">با من صحبت کنید و من سعی می‌کنم با استفاده از دوربین و میکروفون شما، محیط را درک کنم.</p>

        <!-- بخش نمایش دوربین -->
        <div class="relative w-full aspect-video bg-gray-900 rounded-lg overflow-hidden border-2 border-gray-700">
            <video id="webcam" class="w-full h-full object-cover" autoplay playsinline></video>
            <canvas id="canvas" class="hidden"></canvas>
            <div id="loading-overlay" class="absolute inset-0 bg-black bg-opacity-70 flex-col items-center justify-center hidden">
                 <div class="w-16 h-16 border-4 border-dashed rounded-full animate-spin border-blue-500"></div>
                 <p class="mt-4 text-lg">در حال پردازش تصویر و صدا...</p>
            </div>
        </div>

        <!-- کنترل‌ها و وضعیت -->
        <div class="flex flex-col md:flex-row items-center justify-center gap-4">
            <button id="startButton" class="w-full md:w-auto bg-blue-600 hover:bg-blue-700 text-white font-bold py-3 px-6 rounded-lg transition-all duration-300 transform hover:scale-105">
                شروع به کار
            </button>
            <div id="status" class="text-center p-3 rounded-lg bg-gray-700 text-yellow-400 min-w-[200px]">
                وضعیت: آماده‌سازی
            </div>
        </div>

        <!-- بخش گفتگو -->
        <div class="space-y-4">
            <div class="bg-gray-700 p-4 rounded-lg">
                <h2 class="text-lg font-semibold text-blue-300 mb-2">متن شناسایی شده از صدای شما:</h2>
                <p id="user-text" class="text-gray-300 min-h-[50px]">...</p>
            </div>
            <div class="bg-gray-700 p-4 rounded-lg">
                <h2 class="text-lg font-semibold text-green-300 mb-2">پاسخ هوش مصنوعی:</h2>
                <p id="ai-response" class="text-gray-200 min-h-[50px]">...</p>
            </div>
        </div>
    </div>

    <script>
        // دریافت المان‌های HTML
        const startButton = document.getElementById('startButton');
        const webcamVideo = document.getElementById('webcam');
        const canvas = document.getElementById('canvas');
        const statusDiv = document.getElementById('status');
        const userTextDiv = document.getElementById('user-text');
        const aiResponseDiv = document.getElementById('ai-response');
        const loadingOverlay = document.getElementById('loading-overlay');

        let isListening = false;
        let mediaStream = null;

        // --- بخش ۲ (ب): پردازش گفتار (گوش‌ها) ---
        // راه‌اندازی API تشخیص گفتار مرورگر
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;
        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.continuous = false; // فقط یک بار گوش می‌دهد
            recognition.lang = 'fa-IR'; // زبان فارسی
            recognition.interimResults = false;
        } else {
            statusDiv.textContent = 'تشخیص گفتار پشتیبانی نمی‌شود';
            startButton.disabled = true;
        }

        // --- بخش ۱ (الف): بینایی کامپیوتری (چشم‌ها) ---
        // تابع برای شروع به کار دوربین
        async function startWebcam() {
            try {
                mediaStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
                webcamVideo.srcObject = mediaStream;
                statusDiv.textContent = 'دوربین و میکروفون فعال شد. صحبت کنید.';
                startButton.textContent = 'در حال شنیدن...';
                startButton.classList.add('glowing-border');
                isListening = true;
                recognition.start(); // شروع به گوش دادن
            } catch (err) {
                console.error("خطا در دسترسی به دوربین/میکروفون:", err);
                statusDiv.textContent = 'خطا در دسترسی به مدیا';
                alert('لطفاً اجازه دسترسی به دوربین و میکروفون را بدهید.');
            }
        }

        // تابع برای گرفتن یک فریم از ویدیو
        function captureFrame() {
            canvas.width = webcamVideo.videoWidth;
            canvas.height = webcamVideo.videoHeight;
            const context = canvas.getContext('2d');
            context.drawImage(webcamVideo, 0, 0, canvas.width, canvas.height);
            // تبدیل تصویر به فرمت Base64
            return canvas.toDataURL('image/jpeg').split(',')[1];
        }

        // رویداد کلیک روی دکمه شروع
        startButton.addEventListener('click', () => {
            if (!isListening) {
                startWebcam();
            }
        });

        // رویداد وقتی تشخیص گفتار نتیجه‌ای را برمی‌گرداند
        recognition.onresult = (event) => {
            const transcript = event.results[0][0].transcript;
            userTextDiv.textContent = transcript;
            statusDiv.textContent = 'در حال تحلیل...';
            loadingOverlay.classList.remove('hidden');
            loadingOverlay.classList.add('flex');


            // در لحظه اتمام صحبت، یک فریم از دوربین بگیر
            const imageBase64 = captureFrame();
            
            // --- بخش ۲: مغز متفکر (ارسال به Gemini) ---
            callGeminiAPI(transcript, imageBase64);
        };

        // رویداد وقتی گوش دادن تمام می‌شود
        recognition.onend = () => {
            if (isListening) {
                recognition.start(); // دوباره شروع به گوش دادن کن
            }
        };
        
        recognition.onerror = (event) => {
            console.error("خطای تشخیص گفتار:", event.error);
            if(event.error === 'no-speech') {
                 // این خطا طبیعی است اگر کاربر صحبت نکند، نیازی به نمایش به کاربر نیست
            } else {
                statusDiv.textContent = `خطا: ${event.error}`;
            }
        };


        // --- بخش ۲ و ۳: شناخت و تولید (ارتباط با Gemini و پاسخ) ---
        async function callGeminiAPI(text, imageBase64) {
            const apiKey = ""; // کلید API در محیط Canvas به صورت خودکار تزریق می‌شود
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;

            const payload = {
                contents: [
                    {
                        role: "user",
                        parts: [
                            { text: `شما یک ربات انسان‌نما هستید. بر اساس این تصویر و سوال کاربر، یک پاسخ کوتاه و مفید به زبان فارسی بدهید. سوال کاربر: "${text}"` },
                            {
                                inlineData: {
                                    mimeType: "image/jpeg",
                                    data: imageBase64
                                }
                            }
                        ]
                    }
                ]
            };

            try {
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }

                const result = await response.json();
                let aiText = "متاسفانه نتوانستم پاسخی تولید کنم.";
                if (result.candidates && result.candidates.length > 0 &&
                    result.candidates[0].content && result.candidates[0].content.parts &&
                    result.candidates[0].content.parts.length > 0) {
                    aiText = result.candidates[0].content.parts[0].text;
                }
                
                aiResponseDiv.textContent = aiText;
                // --- بخش ۳ (الف): متن به گفتار (صدا) ---
                speak(aiText);

            } catch (error) {
                console.error("خطا در ارتباط با Gemini API:", error);
                aiResponseDiv.textContent = "خطایی در ارتباط با سرور هوش مصنوعی رخ داد.";
            } finally {
                statusDiv.textContent = 'آماده دریافت فرمان بعدی. صحبت کنید.';
                loadingOverlay.classList.add('hidden');
                loadingOverlay.classList.remove('flex');
            }
        }

        // تابع برای صحبت کردن متن
        function speak(text) {
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.lang = 'fa-IR'; // تنظیم زبان برای صدای فارسی
            utterance.rate = 0.9;
            window.speechSynthesis.speak(utterance);
        }

    </script>
</body>
</html>
